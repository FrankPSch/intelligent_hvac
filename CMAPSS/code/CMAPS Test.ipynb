{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the C-MAPPS benchmark. Approach using MLP. \n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\controlslab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import CMAPSAuxFunctions\n",
    "#import plottingTools\n",
    "#from datetime import datetime\n",
    "#from sklearn.covariance import EllipticEnvelope\n",
    "#from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#from sklearn.dummy import DummyClassifier\n",
    "#from sklearn.model_selection import train_test_split, cross_validate\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "#from dataManagement import DataManagerDamadics\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "%matplotlib notebook\n",
    "\n",
    "global constRUL\n",
    "\n",
    "constRUL = 125\n",
    "time_window = 30\n",
    "rul_vector = None\n",
    "\n",
    "CMAPSAuxFunctions.set_const_RUL(constRUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve and Reshape data\n",
    "\n",
    "Get the data from the text files, store it in a Pandas Dataframe and reshape it as appropiately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_train = '../CMAPSSData/train_FD001.txt'\n",
    "data_file_test = '../CMAPSSData/test_FD001.txt'\n",
    "\n",
    "#min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "standardScaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "#Selected as per CNN paper\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "#Get the X and y matrices with the specified time window\n",
    "X_train, y_train = CMAPSAuxFunctions.retrieve_and_reshape_data(data_file_train, selected_features, time_window, 'train')\n",
    "X_test, _ = CMAPSAuxFunctions.retrieve_and_reshape_data(data_file_test, selected_features, time_window, 'test')\n",
    "y_test = np.loadtxt(\"../CMAPSSData/RUL_FD001.txt\")\n",
    "y_test = np.array([x if x < constRUL else constRUL for x in y_test])\n",
    "y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
    "\n",
    "#Standardize the data\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "(17731, 420)\n",
      "(17731, 1)\n",
      "Testing data\n",
      "(100, 420)\n",
      "(100, 1)\n",
      "Training data\n",
      "[[ 0.62199313  0.32071611  0.36067504 ...  0.45454545 -0.4488189\n",
      "  -0.77474791]\n",
      " [ 0.20962199  0.14475703  0.60204082 ...  0.09090909 -0.7480315\n",
      "  -0.24669791]\n",
      " [ 0.12714777  0.14475703  0.71428571 ...  0.63636364 -0.52755906\n",
      "  -0.88893623]\n",
      " [ 0.03092784  0.14475703  0.78296703 ...  0.09090909 -0.76377953\n",
      "  -0.51768215]\n",
      " [ 0.26460481  0.15191816  0.50039246 ...  0.27272727 -0.63779528\n",
      "  -0.55120011]]\n",
      "[[4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Testing data\n",
      "[[-0.72682927 -0.95827124 -0.89279113 ... -0.71428571  0.45238095\n",
      "   0.84135021]\n",
      " [ 0.13170732 -0.44336811 -0.39149723 ...  0.42857143 -0.38095238\n",
      "   0.14388186]\n",
      " [-0.08292683 -0.01266766 -0.3323475  ...  0.14285714 -0.02380952\n",
      "   0.42025316]\n",
      " [-0.49268293 -0.23919523 -0.92310536 ... -0.71428571  0.42857143\n",
      "   0.41476793]\n",
      " [-0.32682927 -0.11698957  0.06617375 ...  0.71428571 -0.16666667\n",
      "  -0.31940928]]\n",
      "[[125.]\n",
      " [ 82.]\n",
      " [ 59.]\n",
      " [117.]\n",
      " [ 20.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Testing data\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\"Training data\")\n",
    "print(X_train[-5:,:])\n",
    "print(y_train[-5:,:])\n",
    "print(\"Testing data\")\n",
    "print(X_test[-5:,:])\n",
    "print(y_test[-5:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model\n",
    "\n",
    "We will use a very simple ANN for this example. The model is Dense(ReLU, 100)->Dense(ReLu, 100)->Dense(Linear, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RULmodel(input_shape):\n",
    "    \n",
    "    print(input_shape)\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(1000, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='relu', kernel_initializer='glorot_normal', name='fc2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Dense(100, activation='relu', name='fc3'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(10, activation='relu', name='fc4'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    #create a placeholder for the input\n",
    "    #X_input = Input(shape=(input_shape))\n",
    "    \n",
    "    #Create the layers\n",
    "    #X = Dense(100, activation='relu', name='fc1')(X_input)\n",
    "    #X = Dense(100, activation='relu', name='fc2')(X)\n",
    "    #X = Dense(1, activation='linear', name='out')(X)\n",
    "    \n",
    "    # Create model. This creates the Keras model instance, you'll use this instance to train/test the model.\n",
    "    #model = Sequential(inputs = X_input, outputs = X, name='RUL')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the keras model\n",
    "\n",
    "Fit the Keras model to the data and determine its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "WARNING:tensorflow:From C:\\Users\\controlslab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/250\n",
      "17731/17731 [==============================] - 1s 49us/step - loss: 792.2117 - mean_squared_error: 792.2117\n",
      "Epoch 2/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 248.9294 - mean_squared_error: 248.9294\n",
      "Epoch 3/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 232.3934 - mean_squared_error: 232.3934\n",
      "Epoch 4/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 225.7287 - mean_squared_error: 225.7287\n",
      "Epoch 5/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 224.6628 - mean_squared_error: 224.6628\n",
      "Epoch 6/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 219.2414 - mean_squared_error: 219.2414\n",
      "Epoch 7/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 212.7931 - mean_squared_error: 212.7931\n",
      "Epoch 8/250\n",
      "17731/17731 [==============================] - 1s 34us/step - loss: 206.0885 - mean_squared_error: 206.0885\n",
      "Epoch 9/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 201.4648 - mean_squared_error: 201.4648\n",
      "Epoch 10/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 202.7365 - mean_squared_error: 202.7365\n",
      "Epoch 11/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 198.6071 - mean_squared_error: 198.6071\n",
      "Epoch 12/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 196.1822 - mean_squared_error: 196.1822\n",
      "Epoch 13/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 195.2836 - mean_squared_error: 195.2836\n",
      "Epoch 14/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 190.0603 - mean_squared_error: 190.0603\n",
      "Epoch 15/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 188.2009 - mean_squared_error: 188.2009\n",
      "Epoch 16/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 186.1589 - mean_squared_error: 186.1589\n",
      "Epoch 17/250\n",
      "17731/17731 [==============================] - 1s 35us/step - loss: 186.4438 - mean_squared_error: 186.4438 0s - loss: 183.0002 - mean_squared_err\n",
      "Epoch 18/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 186.7014 - mean_squared_error: 186.7014\n",
      "Epoch 19/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 185.4134 - mean_squared_error: 185.4134\n",
      "Epoch 20/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 178.2892 - mean_squared_error: 178.2892\n",
      "Epoch 21/250\n",
      "17731/17731 [==============================] - 1s 33us/step - loss: 185.3124 - mean_squared_error: 185.3124\n",
      "Epoch 22/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 171.5144 - mean_squared_error: 171.5144\n",
      "Epoch 23/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 167.5913 - mean_squared_error: 167.5913\n",
      "Epoch 24/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 169.3433 - mean_squared_error: 169.3433\n",
      "Epoch 25/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 172.5469 - mean_squared_error: 172.5469\n",
      "Epoch 26/250\n",
      "17731/17731 [==============================] - 1s 40us/step - loss: 166.8206 - mean_squared_error: 166.8206\n",
      "Epoch 27/250\n",
      "17731/17731 [==============================] - 1s 33us/step - loss: 161.1901 - mean_squared_error: 161.1901\n",
      "Epoch 28/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 161.7052 - mean_squared_error: 161.7052\n",
      "Epoch 29/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 157.2469 - mean_squared_error: 157.2469\n",
      "Epoch 30/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 156.3659 - mean_squared_error: 156.3659\n",
      "Epoch 31/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 160.4222 - mean_squared_error: 160.4222\n",
      "Epoch 32/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 152.5685 - mean_squared_error: 152.5685\n",
      "Epoch 33/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 158.5784 - mean_squared_error: 158.5784\n",
      "Epoch 34/250\n",
      "17731/17731 [==============================] - 1s 33us/step - loss: 146.1625 - mean_squared_error: 146.1625\n",
      "Epoch 35/250\n",
      "17731/17731 [==============================] - 1s 47us/step - loss: 150.0821 - mean_squared_error: 150.0821\n",
      "Epoch 36/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 147.1632 - mean_squared_error: 147.1632\n",
      "Epoch 37/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 147.8561 - mean_squared_error: 147.8561\n",
      "Epoch 38/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 143.9962 - mean_squared_error: 143.9962\n",
      "Epoch 39/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 143.0994 - mean_squared_error: 143.0994\n",
      "Epoch 40/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 141.1785 - mean_squared_error: 141.1785\n",
      "Epoch 41/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 136.4757 - mean_squared_error: 136.4757\n",
      "Epoch 42/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 139.8857 - mean_squared_error: 139.8857\n",
      "Epoch 43/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 144.1815 - mean_squared_error: 144.1815\n",
      "Epoch 44/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 131.7312 - mean_squared_error: 131.7312\n",
      "Epoch 45/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 136.7793 - mean_squared_error: 136.7793\n",
      "Epoch 46/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 131.8471 - mean_squared_error: 131.8471\n",
      "Epoch 47/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 128.6326 - mean_squared_error: 128.6326\n",
      "Epoch 48/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 124.2323 - mean_squared_error: 124.2323\n",
      "Epoch 49/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 131.9082 - mean_squared_error: 131.9082\n",
      "Epoch 50/250\n",
      "17731/17731 [==============================] - 1s 33us/step - loss: 124.2872 - mean_squared_error: 124.2872\n",
      "Epoch 51/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 126.6588 - mean_squared_error: 126.6588\n",
      "Epoch 52/250\n",
      "17731/17731 [==============================] - 1s 35us/step - loss: 121.9439 - mean_squared_error: 121.9439\n",
      "Epoch 53/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 124.6047 - mean_squared_error: 124.6047\n",
      "Epoch 54/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 121.7300 - mean_squared_error: 121.7300\n",
      "Epoch 55/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 121.7192 - mean_squared_error: 121.7192\n",
      "Epoch 56/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 124.6058 - mean_squared_error: 124.6058\n",
      "Epoch 57/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 117.7291 - mean_squared_error: 117.7291\n",
      "Epoch 58/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 115.3094 - mean_squared_error: 115.3094 0s - loss: 114.8000 - mean_squared_error: \n",
      "Epoch 59/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 115.5637 - mean_squared_error: 115.5637\n",
      "Epoch 60/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 116.4401 - mean_squared_error: 116.4401\n",
      "Epoch 61/250\n",
      "17731/17731 [==============================] - 1s 36us/step - loss: 116.3346 - mean_squared_error: 116.3346\n",
      "Epoch 62/250\n",
      "17731/17731 [==============================] - 1s 38us/step - loss: 113.4696 - mean_squared_error: 113.4696\n",
      "Epoch 63/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 113.9547 - mean_squared_error: 113.9547\n",
      "Epoch 64/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 112.6593 - mean_squared_error: 112.6593\n",
      "Epoch 65/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17731/17731 [==============================] - 1s 32us/step - loss: 113.9465 - mean_squared_error: 113.9465\n",
      "Epoch 66/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 111.9333 - mean_squared_error: 111.9333\n",
      "Epoch 67/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 113.6865 - mean_squared_error: 113.6865\n",
      "Epoch 68/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 109.8031 - mean_squared_error: 109.8031\n",
      "Epoch 69/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 108.1702 - mean_squared_error: 108.1702\n",
      "Epoch 70/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 110.0548 - mean_squared_error: 110.0548\n",
      "Epoch 71/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 108.0105 - mean_squared_error: 108.0105\n",
      "Epoch 72/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 111.2071 - mean_squared_error: 111.2071\n",
      "Epoch 73/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 112.6376 - mean_squared_error: 112.6376\n",
      "Epoch 74/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 106.6217 - mean_squared_error: 106.6217\n",
      "Epoch 75/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 106.4176 - mean_squared_error: 106.4176\n",
      "Epoch 76/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 106.2904 - mean_squared_error: 106.2904\n",
      "Epoch 77/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 104.1026 - mean_squared_error: 104.1026\n",
      "Epoch 78/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 102.1055 - mean_squared_error: 102.1055\n",
      "Epoch 79/250\n",
      "17731/17731 [==============================] - 1s 33us/step - loss: 99.7873 - mean_squared_error: 99.7873\n",
      "Epoch 80/250\n",
      "17731/17731 [==============================] - 1s 37us/step - loss: 102.7079 - mean_squared_error: 102.7079\n",
      "Epoch 81/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 101.4584 - mean_squared_error: 101.4584\n",
      "Epoch 82/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 100.5270 - mean_squared_error: 100.5270\n",
      "Epoch 83/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 98.2497 - mean_squared_error: 98.2497 0s - loss: 98.2613 - mean_squared_erro\n",
      "Epoch 84/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 96.2055 - mean_squared_error: 96.2055\n",
      "Epoch 85/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 100.9553 - mean_squared_error: 100.9553\n",
      "Epoch 86/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 97.5837 - mean_squared_error: 97.5837\n",
      "Epoch 87/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 97.4062 - mean_squared_error: 97.4062\n",
      "Epoch 88/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 100.0992 - mean_squared_error: 100.0992\n",
      "Epoch 89/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 98.9241 - mean_squared_error: 98.9241\n",
      "Epoch 90/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 101.3644 - mean_squared_error: 101.3644\n",
      "Epoch 91/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 94.0036 - mean_squared_error: 94.0036\n",
      "Epoch 92/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 99.8297 - mean_squared_error: 99.8297\n",
      "Epoch 93/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 98.4520 - mean_squared_error: 98.4520\n",
      "Epoch 94/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 95.6365 - mean_squared_error: 95.6365\n",
      "Epoch 95/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 90.3014 - mean_squared_error: 90.3014\n",
      "Epoch 96/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 93.8074 - mean_squared_error: 93.8074\n",
      "Epoch 97/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 93.7189 - mean_squared_error: 93.7189\n",
      "Epoch 98/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 90.3646 - mean_squared_error: 90.3646\n",
      "Epoch 99/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 93.0857 - mean_squared_error: 93.0857\n",
      "Epoch 100/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 90.6832 - mean_squared_error: 90.6832\n",
      "Epoch 101/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 91.3953 - mean_squared_error: 91.3953\n",
      "Epoch 102/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 91.4975 - mean_squared_error: 91.4975\n",
      "Epoch 103/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 89.4275 - mean_squared_error: 89.4275\n",
      "Epoch 104/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 89.6483 - mean_squared_error: 89.6483\n",
      "Epoch 105/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 93.0226 - mean_squared_error: 93.0226\n",
      "Epoch 106/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 89.8771 - mean_squared_error: 89.8771\n",
      "Epoch 107/250\n",
      "17731/17731 [==============================] - 1s 40us/step - loss: 88.5801 - mean_squared_error: 88.5801\n",
      "Epoch 108/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 90.4230 - mean_squared_error: 90.4230\n",
      "Epoch 109/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 88.8726 - mean_squared_error: 88.8726\n",
      "Epoch 110/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 90.2243 - mean_squared_error: 90.2243\n",
      "Epoch 111/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 88.4816 - mean_squared_error: 88.4816\n",
      "Epoch 112/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 89.6220 - mean_squared_error: 89.6220\n",
      "Epoch 113/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 86.9040 - mean_squared_error: 86.9040\n",
      "Epoch 114/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 91.5755 - mean_squared_error: 91.5755\n",
      "Epoch 115/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 84.5733 - mean_squared_error: 84.5733\n",
      "Epoch 116/250\n",
      "17731/17731 [==============================] - 1s 37us/step - loss: 85.9578 - mean_squared_error: 85.9578\n",
      "Epoch 117/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 87.0314 - mean_squared_error: 87.0314\n",
      "Epoch 118/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 87.7582 - mean_squared_error: 87.7582\n",
      "Epoch 119/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 84.6652 - mean_squared_error: 84.6652\n",
      "Epoch 120/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 84.7830 - mean_squared_error: 84.7830\n",
      "Epoch 121/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 86.3170 - mean_squared_error: 86.3170\n",
      "Epoch 122/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 86.8115 - mean_squared_error: 86.8115\n",
      "Epoch 123/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 84.6963 - mean_squared_error: 84.6963\n",
      "Epoch 124/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 82.8437 - mean_squared_error: 82.8437\n",
      "Epoch 125/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 93.5868 - mean_squared_error: 93.5868\n",
      "Epoch 126/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 82.8627 - mean_squared_error: 82.8627\n",
      "Epoch 127/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 82.5900 - mean_squared_error: 82.5900\n",
      "Epoch 128/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 79.3783 - mean_squared_error: 79.3783\n",
      "Epoch 129/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 83.7250 - mean_squared_error: 83.7250\n",
      "Epoch 130/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 82.9907 - mean_squared_error: 82.9907\n",
      "Epoch 131/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 82.1891 - mean_squared_error: 82.1891\n",
      "Epoch 132/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 77.1140 - mean_squared_error: 77.1140\n",
      "Epoch 133/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17731/17731 [==============================] - 1s 31us/step - loss: 78.0397 - mean_squared_error: 78.0397\n",
      "Epoch 134/250\n",
      "17731/17731 [==============================] - 1s 33us/step - loss: 79.8823 - mean_squared_error: 79.8823\n",
      "Epoch 135/250\n",
      "17731/17731 [==============================] - 1s 39us/step - loss: 81.9460 - mean_squared_error: 81.9460\n",
      "Epoch 136/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 83.9806 - mean_squared_error: 83.9806\n",
      "Epoch 137/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 74.9875 - mean_squared_error: 74.9875\n",
      "Epoch 138/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 79.1162 - mean_squared_error: 79.1162\n",
      "Epoch 139/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 77.5194 - mean_squared_error: 77.5194\n",
      "Epoch 140/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 76.6671 - mean_squared_error: 76.6671\n",
      "Epoch 141/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 77.3073 - mean_squared_error: 77.3073\n",
      "Epoch 142/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 76.7501 - mean_squared_error: 76.7501\n",
      "Epoch 143/250\n",
      "17731/17731 [==============================] - 1s 34us/step - loss: 79.4318 - mean_squared_error: 79.4318\n",
      "Epoch 144/250\n",
      "17731/17731 [==============================] - 1s 36us/step - loss: 77.2403 - mean_squared_error: 77.2403 0s - loss: 77.4564 - mean_squared_error: 77.\n",
      "Epoch 145/250\n",
      "17731/17731 [==============================] - 1s 32us/step - loss: 79.2727 - mean_squared_error: 79.2727\n",
      "Epoch 146/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 82.0522 - mean_squared_error: 82.0522\n",
      "Epoch 147/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 77.0283 - mean_squared_error: 77.0283\n",
      "Epoch 148/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 80.0887 - mean_squared_error: 80.0887\n",
      "Epoch 149/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 76.8347 - mean_squared_error: 76.8347\n",
      "Epoch 150/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 75.6462 - mean_squared_error: 75.6462\n",
      "Epoch 151/250\n",
      "17731/17731 [==============================] - 1s 30us/step - loss: 74.1451 - mean_squared_error: 74.1451\n",
      "Epoch 152/250\n",
      "17731/17731 [==============================] - 1s 31us/step - loss: 74.1321 - mean_squared_error: 74.1321\n",
      "Epoch 153/250\n",
      " 1792/17731 [==>...........................] - ETA: 0s - loss: 74.7108 - mean_squared_error: 74.7108"
     ]
    }
   ],
   "source": [
    "#Create the model\n",
    "modelRUL = RULmodel(X_train.shape[1])\n",
    "\n",
    "#Compile the model.\n",
    "modelRUL.compile(optimizer = \"adam\", loss = \"mean_squared_error\", metrics = [\"mse\"])\n",
    "\n",
    "startTime = time.clock()\n",
    "#Train the model.\n",
    "modelRUL.fit(x = X_train, y = y_train, epochs = 250, batch_size = 128)  \n",
    "endTime = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 431us/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'CMAPSAuxFunctions' has no attribute 'compute_health_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-877288467db9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelRUL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelRUL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhealtScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCMAPSAuxFunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_health_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Root Square Mean Error score: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'CMAPSAuxFunctions' has no attribute 'compute_health_score'"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "score = modelRUL.evaluate(x = X_test, y = y_test)\n",
    "y_pred = modelRUL.predict(X_test)\n",
    "healtScore = CMAPSAuxFunctions.compute_health_score(y_test, y_pred)\n",
    "\n",
    "print(\"Root Square Mean Error score: {}\".format(np.sqrt(score[0])))\n",
    "print(\"Health score: {}\".format(healtScore))\n",
    "print(\"Elapsed time: {}\".format(endTime - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "(17731, 420)\n",
      "(17731, 1)\n",
      "Testing data\n",
      "(100, 420)\n",
      "(100, 1)\n",
      "Training data\n",
      "[[ 0.62199313  0.32071611  0.36067504 ...  0.45454545 -0.4488189\n",
      "  -0.77474791]\n",
      " [ 0.20962199  0.14475703  0.60204082 ...  0.09090909 -0.7480315\n",
      "  -0.24669791]\n",
      " [ 0.12714777  0.14475703  0.71428571 ...  0.63636364 -0.52755906\n",
      "  -0.88893623]\n",
      " [ 0.03092784  0.14475703  0.78296703 ...  0.09090909 -0.76377953\n",
      "  -0.51768215]\n",
      " [ 0.26460481  0.15191816  0.50039246 ...  0.27272727 -0.63779528\n",
      "  -0.55120011]]\n",
      "[[4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Testing data\n",
      "[[-0.72682927 -0.95827124 -0.89279113 ... -0.71428571  0.45238095\n",
      "   0.84135021]\n",
      " [ 0.13170732 -0.44336811 -0.39149723 ...  0.42857143 -0.38095238\n",
      "   0.14388186]\n",
      " [-0.08292683 -0.01266766 -0.3323475  ...  0.14285714 -0.02380952\n",
      "   0.42025316]\n",
      " [-0.49268293 -0.23919523 -0.92310536 ... -0.71428571  0.42857143\n",
      "   0.41476793]\n",
      " [-0.32682927 -0.11698957  0.06617375 ...  0.71428571 -0.16666667\n",
      "  -0.31940928]]\n",
      "[[125.]\n",
      " [ 82.]\n",
      " [ 59.]\n",
      " [117.]\n",
      " [ 20.]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Net approach\n",
    "\n",
    "The approach used in the original paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureN = 14\n",
    "nb_epoch = 250\n",
    "batch_size = 512\n",
    "FilterN = 10\n",
    "FilterL = 10\n",
    "rmse,sco,tm = [], [], []\n",
    "\n",
    "ConstRUL = 125\n",
    "TW = 30\n",
    "Dataset = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the train and test data from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seed = 2222\\nnp.random.seed(seed)\\nnp.random.shuffle(samples)\\nnp.random.seed(seed)\\nnp.random.shuffle(targets)\\nsamplet = samplet[np.argsort(labelt)]\\nlabelt = labelt[np.argsort(labelt)]'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ training samples ##################################\n",
    "\n",
    "setTrain = {'1':100, '2':260, '3':100, '4':248}\n",
    "setTest = {'1':100, '2':259, '3':100, '4':248}\n",
    "nTrain = setTrain[Dataset]\n",
    "nTest = setTest[Dataset]\n",
    "\n",
    "data = [] \n",
    "for line in open(\"../CMAPSSData/train_FD00\"+Dataset+\".txt\"):\n",
    "    data.append(line.split())\n",
    "data=np.array(data)\n",
    "data = np.cast['float64'](data)\n",
    "data_copy = data\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "data = min_max_scaler.fit_transform(data)   #Why scale the data with all of the \"missing\" rows.\n",
    "num=[]\n",
    "for i in range(nTrain):\n",
    "    tmp = data[np.where(data_copy[:,0]==i+1),:][0][:, np.array([6,7,8,11,12,13,15,16,17,18,19,21,24,25])]\n",
    "    num.append(tmp)\n",
    "num=np.array(num)\n",
    "\n",
    "label=[]\n",
    "for i in range(nTrain):\n",
    "    label.append([])\n",
    "    length = len(num[i])\n",
    "    for j in range(length):\n",
    "        label[i].append(ConstRUL if length-j-1>=ConstRUL else length-j-1)\n",
    "label = np.array(label)\n",
    "\n",
    "samples,targets,noofsample = [],[],[]\n",
    "for i in range(nTrain):\n",
    "    noofsample.append(len(num[i])-TW+1)\n",
    "    for j in range(noofsample[-1]):\n",
    "        samples.append(num[i][j:j+TW,:])\n",
    "        targets.append(label[i][j+TW-1])\n",
    "samples = np.array(samples)\n",
    "targets = np.array(targets)\n",
    "\n",
    "################## testing data ###########################\n",
    "data = [] \n",
    "for line in open(\"../CMAPSSData/test_FD00\"+Dataset+\".txt\"):\n",
    "    data.append(line.split())\n",
    "data=np.array(data)\n",
    "data = np.cast['float64'](data)\n",
    "data_copy = data\n",
    "data = min_max_scaler.transform(data)  #Why scale the data with all of the \"missing\" rows.\n",
    "numt=[]\n",
    "for i in range(nTest):\n",
    "    tmp = data[np.where(data_copy[:,0]==i+1),:][0][:, np.array([6,7,8,11,12,13,15,16,17,18,19,21,24,25])]\n",
    "    numt.append(tmp)\n",
    "numt=np.array(numt)\n",
    "\n",
    "samplet, count_miss = [],[]\n",
    "for i in range(nTest):\n",
    "    if len(numt[i])>=TW:\n",
    "        samplet.append(numt[i][-TW:,:])\n",
    "    else:\n",
    "        count_miss.append(i)\n",
    "samplet = np.array(samplet)\n",
    "\n",
    "labelt = [] \n",
    "for line in open(\"../CMAPSSData/RUL_FD00\"+Dataset+\".txt\"):\n",
    "    labelt.append(line.split())\n",
    "labelt = np.cast['int32'](labelt)\n",
    "labelnew = []\n",
    "for i in range(nTest):\n",
    "    if i not in count_miss:\n",
    "        #labelnew.append(labelt[i][0])\n",
    "        labelnew.append(labelt[i][0] if labelt[i][0]<=ConstRUL else ConstRUL)\n",
    "labelt = labelnew\n",
    "labelt=np.array(labelt)\n",
    "\n",
    "'''seed = 2222\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(samples)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(targets)\n",
    "samplet = samplet[np.argsort(labelt)]\n",
    "labelt = labelt[np.argsort(labelt)]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "(17731, 30, 14)\n",
      "(17731,)\n",
      "Testing data\n",
      "(100, 30, 14)\n",
      "(100,)\n",
      "Training data\n",
      "[[[ 0.42168675  0.12579028  0.17049291 ...  0.33333333 -0.27131783\n",
      "   -0.07953604]\n",
      "  [ 0.06024096 -0.02419882  0.37812289 ...  0.16666667 -0.27131783\n",
      "    0.01712234]\n",
      "  [-0.01204819 -0.02419882  0.47467927 ...  0.16666667 -0.11627907\n",
      "   -0.11101906]\n",
      "  ...\n",
      "  [ 0.51204819  0.14453891  0.52464551 ...  0.         -0.62790698\n",
      "   -0.34217067]\n",
      "  [ 0.3253012   0.26444299  0.67623228 ...  0.         -1.\n",
      "   -0.17674676]\n",
      "  [ 0.37349398  0.17462394  0.5658339  ...  0.5        -0.45736434\n",
      "   -0.78099972]]\n",
      "\n",
      " [[ 0.06024096 -0.02419882  0.37812289 ...  0.16666667 -0.27131783\n",
      "    0.01712234]\n",
      "  [-0.01204819 -0.02419882  0.47467927 ...  0.16666667 -0.11627907\n",
      "   -0.11101906]\n",
      "  [-0.09638554 -0.02419882  0.53376097 ...  0.         -0.24031008\n",
      "   -0.2761668 ]\n",
      "  ...\n",
      "  [ 0.3253012   0.26444299  0.67623228 ...  0.         -1.\n",
      "   -0.17674676]\n",
      "  [ 0.37349398  0.17462394  0.5658339  ...  0.5        -0.45736434\n",
      "   -0.78099972]\n",
      "  [ 0.40361446  0.4589056   0.73295071 ...  0.16666667 -0.75193798\n",
      "   -0.26760563]]\n",
      "\n",
      " [[-0.01204819 -0.02419882  0.47467927 ...  0.16666667 -0.11627907\n",
      "   -0.11101906]\n",
      "  [-0.09638554 -0.02419882  0.53376097 ...  0.         -0.24031008\n",
      "   -0.2761668 ]\n",
      "  [ 0.10843373 -0.01809462  0.29068197 ...  0.33333333  0.03875969\n",
      "   -0.28997514]\n",
      "  ...\n",
      "  [ 0.37349398  0.17462394  0.5658339  ...  0.5        -0.45736434\n",
      "   -0.78099972]\n",
      "  [ 0.40361446  0.4589056   0.73295071 ...  0.16666667 -0.75193798\n",
      "   -0.26760563]\n",
      "  [ 0.3313253   0.36995858  0.55064146 ...  0.66666667 -0.53488372\n",
      "   -0.89201878]]\n",
      "\n",
      " [[-0.09638554 -0.02419882  0.53376097 ...  0.         -0.24031008\n",
      "   -0.2761668 ]\n",
      "  [ 0.10843373 -0.01809462  0.29068197 ...  0.33333333  0.03875969\n",
      "   -0.28997514]\n",
      "  [ 0.06024096  0.36516242  0.4409183  ...  0.         -0.45736434\n",
      "   -0.17702292]\n",
      "  ...\n",
      "  [ 0.40361446  0.4589056   0.73295071 ...  0.16666667 -0.75193798\n",
      "   -0.26760563]\n",
      "  [ 0.3313253   0.36995858  0.55064146 ...  0.66666667 -0.53488372\n",
      "   -0.89201878]\n",
      "  [ 0.21686747  0.49204273  0.49493585 ...  0.16666667 -0.76744186\n",
      "   -0.53106877]]\n",
      "\n",
      " [[ 0.10843373 -0.01809462  0.29068197 ...  0.33333333  0.03875969\n",
      "   -0.28997514]\n",
      "  [ 0.06024096  0.36516242  0.4409183  ...  0.         -0.45736434\n",
      "   -0.17702292]\n",
      "  [ 0.31927711  0.06780031  0.22822417 ... -0.16666667 -0.56589147\n",
      "   -0.21264844]\n",
      "  ...\n",
      "  [ 0.3313253   0.36995858  0.55064146 ...  0.66666667 -0.53488372\n",
      "   -0.89201878]\n",
      "  [ 0.21686747  0.49204273  0.49493585 ...  0.16666667 -0.76744186\n",
      "   -0.53106877]\n",
      "  [ 0.59036145  0.2792675   0.68433491 ...  0.33333333 -0.64341085\n",
      "   -0.56365645]]]\n",
      "[4 3 2 1 0]\n",
      "Testing data\n",
      "[[[-0.55421687 -0.61107478 -0.55232951 ... -0.33333333  0.39534884\n",
      "    0.55426678]\n",
      "  [-0.65060241 -0.17680401 -0.75151924 ... -0.33333333  0.28682171\n",
      "    0.14526374]\n",
      "  [-0.55421687 -0.58098975 -0.41458474 ... -0.33333333  0.41085271\n",
      "    0.341066  ]\n",
      "  ...\n",
      "  [-0.46987952  0.10660562 -0.28257934 ... -0.16666667  0.34883721\n",
      "    0.38663353]\n",
      "  [-0.24698795 -0.3381295  -0.24004051 ... -0.16666667  0.51937984\n",
      "    0.11875173]\n",
      "  [-0.34337349 -0.13494659 -0.47029034 ... -0.5         0.27131783\n",
      "    0.56420878]]\n",
      "\n",
      " [[-0.02409639 -0.30978853 -0.32343011 ... -0.33333333  0.37984496\n",
      "    0.25158796]\n",
      "  [-0.1626506  -0.29016787 -0.23869007 ... -0.16666667  0.27131783\n",
      "    0.31593482]\n",
      "  [-0.39156627 -0.29627207 -0.36664416 ... -0.16666667  0.25581395\n",
      "    0.3985087 ]\n",
      "  ...\n",
      "  [-0.40361446 -0.21342926 -0.32039163 ... -0.16666667  0.37984496\n",
      "    0.31759183]\n",
      "  [-0.39156627 -0.39481142 -0.26772451 ... -0.33333333  0.06976744\n",
      "    0.50483292]\n",
      "  [-0.1686747  -0.48027033 -0.03207292 ...  0.16666667 -0.27131783\n",
      "    0.10770505]]\n",
      "\n",
      " [[-0.15662651 -0.05777196 -0.29642134 ... -0.16666667  0.17829457\n",
      "    0.11543772]\n",
      "  [-0.24698795 -0.23348594 -0.11006077 ... -0.16666667  0.1627907\n",
      "    0.1248274 ]\n",
      "  [-0.18072289 -0.24177022 -0.04051317 ... -0.33333333  0.2248062\n",
      "    0.34962717]\n",
      "  ...\n",
      "  [ 0.12048193 -0.27883148  0.05773126 ...  0.16666667 -0.10077519\n",
      "    0.02734051]\n",
      "  [ 0.01204819 -0.03727927 -0.28899392 ...  0.         -0.02325581\n",
      "    0.00303783]\n",
      "  [-0.11445783  0.24133421  0.1215395  ...  0.         -0.03875969\n",
      "    0.28859431]]\n",
      "\n",
      " [[-0.40963855 -0.19032047 -0.56617151 ... -0.66666667  0.42635659\n",
      "    0.32836233]\n",
      "  [-0.62048193 -0.57096141 -0.67555706 ... -0.66666667  0.51937984\n",
      "    0.4084507 ]\n",
      "  [-0.42771084 -0.36908655 -0.486158   ... -0.5         0.95348837\n",
      "    0.48715824]\n",
      "  ...\n",
      "  [-0.04216867 -0.5382603  -0.49729912 ... -0.5         0.44186047\n",
      "    0.08091687]\n",
      "  [-0.3253012  -0.46152169 -0.28865631 ... -0.66666667  0.28682171\n",
      "    0.54045844]\n",
      "  [-0.52409639 -0.39001526 -0.46893991 ... -0.5         0.25581395\n",
      "    0.28500414]]\n",
      "\n",
      " [[-0.30722892 -0.11881404 -0.1144497  ... -0.33333333  0.06976744\n",
      "    0.1996686 ]\n",
      "  [-0.10240964 -0.17680401 -0.13301823 ... -0.16666667  0.14728682\n",
      "    0.11516156]\n",
      "  [-0.02409639 -0.31981687 -0.02295746 ... -0.33333333  0.08527132\n",
      "   -0.12703673]\n",
      "  ...\n",
      "  [ 0.34337349 -0.03597122 -0.17049291 ...  0.16666667 -0.25581395\n",
      "   -0.1413974 ]\n",
      "  [ 0.23493976  0.0442555   0.25286968 ...  0.16666667 -0.19379845\n",
      "    0.03755869]\n",
      "  [ 0.04819277  0.33333333  0.44294396 ...  0.33333333 -0.13178295\n",
      "   -0.1955261 ]]]\n",
      "[125  82  59 117  20]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data\")\n",
    "print(samples.shape)\n",
    "print(targets.shape)\n",
    "print(\"Testing data\")\n",
    "print(samplet.shape)\n",
    "print(labelt.shape)\n",
    "print(\"Training data\")\n",
    "print(samples[-5:,:])\n",
    "print(targets[-5:])\n",
    "print(\"Testing data\")\n",
    "print(samplet[-5:,:])\n",
    "print(labelt[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model\n",
    "\n",
    "CNN model. The model is Dense(ReLU, 100)->Dense(ReLu, 100)->Dense(Linear, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RULCNNModel(TW, FeatureN):\n",
    "    \n",
    "    input_layer = Input(shape=(TW, FeatureN))\n",
    "    y = Reshape((TW, FeatureN, 1), input_shape=(TW, FeatureN, ),name = 'Reshape')(input_layer)\n",
    "\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C1')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C2')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C3')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C4')(y)\n",
    "    #y = Convolution2D(FilterN, FilterL, 1, border_mode='same', init='glorot_normal', activation='tanh', name='C5')(y)\n",
    "    #y = Convolution2D(FilterN, FilterL, 1, border_mode='same', init='glorot_normal', activation='tanh', name='C6')(y)\n",
    "    \n",
    "    y = Conv2D(1, 3, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='Clast')(y)  \n",
    "    \n",
    "    y = Reshape((TW,14))(y)\n",
    "    y = Flatten()(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    \n",
    "    #y = Dense(100, activation='tanh', init='glorot_normal', activity_regularizer=keras.regularizers.l2(0.01),)(y)\n",
    "    y = Dense(100,activation='tanh', kernel_initializer='glorot_normal', name='fc')(y)\n",
    "    y = Dense(1)(y)\n",
    "    \n",
    "    model = Model(inputs = input_layer, outputs = y, name='RUL_CNN_Model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\controlslab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (10, 1), name=\"C1\", padding=\"same\", activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  \n",
      "C:\\Users\\controlslab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (10, 1), name=\"C2\", padding=\"same\", activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  import sys\n",
      "C:\\Users\\controlslab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (10, 1), name=\"C3\", padding=\"same\", activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  \n",
      "C:\\Users\\controlslab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (10, 1), name=\"C4\", padding=\"same\", activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\controlslab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (3, 1), name=\"Clast\", padding=\"same\", activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\controlslab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17731 samples, validate on 100 samples\n",
      "Epoch 1/250\n",
      "17731/17731 [==============================] - 10s 574us/step - loss: 6572.4042 - val_loss: 5025.3726\n",
      "Epoch 2/250\n",
      "17731/17731 [==============================] - 10s 570us/step - loss: 5693.9979 - val_loss: 4600.8364\n",
      "Epoch 3/250\n",
      "10752/17731 [=================>............] - ETA: 3s - loss: 5303.0278"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-2a9f563ae524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m history = DCNN.fit(samples, targets,nb_epoch=nb_epoch, batch_size=batch_size,verbose=1, \n\u001b[1;32m----> 8\u001b[1;33m                    validation_data=(samplet, labelt), callbacks=[lrate])\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#, TensorBoard(log_dir='tmp\\\\tan_4c_4')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2332\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
