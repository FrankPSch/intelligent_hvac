{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the C-MAPPS benchmark. Approach using MLP. \n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\controlslab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, math, random, pickle, time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler,EarlyStopping\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers.pooling import AveragePooling1D, MaxPooling1D\n",
    "from keras.layers import Dense, Dropout, Activation, Input, merge, Convolution2D, Reshape, Flatten, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "import keras\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureN = 14\n",
    "nb_epoch = 250\n",
    "batch_size = 512\n",
    "FilterN = 10\n",
    "FilterL = 10\n",
    "rmse,sco,tm = [], [], []\n",
    "\n",
    "ConstRUL = 125\n",
    "TW = 30\n",
    "Dataset = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the train and test data from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seed = 2222\\nnp.random.seed(seed)\\nnp.random.shuffle(samples)\\nnp.random.seed(seed)\\nnp.random.shuffle(targets)\\nsamplet = samplet[np.argsort(labelt)]\\nlabelt = labelt[np.argsort(labelt)]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ training samples ##################################\n",
    "\n",
    "setTrain = {'1':100, '2':260, '3':100, '4':248}\n",
    "setTest = {'1':100, '2':259, '3':100, '4':248}\n",
    "nTrain = setTrain[Dataset]\n",
    "nTest = setTest[Dataset]\n",
    "\n",
    "data = [] \n",
    "for line in open(\"../CMAPSSData/train_FD00\"+Dataset+\".txt\"):\n",
    "    data.append(line.split())\n",
    "data=np.array(data)\n",
    "data = np.cast['float64'](data)\n",
    "data_copy = data\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "data = min_max_scaler.fit_transform(data)   #Why scale the data with all of the \"missing\" rows.\n",
    "num=[]\n",
    "for i in range(nTrain):\n",
    "    tmp = data[np.where(data_copy[:,0]==i+1),:][0][:, np.array([6,7,8,11,12,13,15,16,17,18,19,21,24,25])]\n",
    "    num.append(tmp)\n",
    "num=np.array(num)\n",
    "\n",
    "label=[]\n",
    "for i in range(nTrain):\n",
    "    label.append([])\n",
    "    length = len(num[i])\n",
    "    for j in range(length):\n",
    "        label[i].append(ConstRUL if length-j-1>=ConstRUL else length-j-1)\n",
    "label = np.array(label)\n",
    "\n",
    "samples,targets,noofsample = [],[],[]\n",
    "for i in range(nTrain):\n",
    "    noofsample.append(len(num[i])-TW+1)\n",
    "    for j in range(noofsample[-1]):\n",
    "        samples.append(num[i][j:j+TW,:])\n",
    "        targets.append(label[i][j+TW-1])\n",
    "samples = np.array(samples)\n",
    "targets = np.array(targets)\n",
    "\n",
    "################## testing data ###########################\n",
    "data = [] \n",
    "for line in open(\"../CMAPSSData/test_FD00\"+Dataset+\".txt\"):\n",
    "    data.append(line.split())\n",
    "data=np.array(data)\n",
    "data = np.cast['float64'](data)\n",
    "data_copy = data\n",
    "data = min_max_scaler.transform(data)  #Why scale the data with all of the \"missing\" rows.\n",
    "numt=[]\n",
    "for i in range(nTest):\n",
    "    tmp = data[np.where(data_copy[:,0]==i+1),:][0][:, np.array([6,7,8,11,12,13,15,16,17,18,19,21,24,25])]\n",
    "    numt.append(tmp)\n",
    "numt=np.array(numt)\n",
    "\n",
    "samplet, count_miss = [],[]\n",
    "for i in range(nTest):\n",
    "    if len(numt[i])>=TW:\n",
    "        samplet.append(numt[i][-TW:,:])\n",
    "    else:\n",
    "        count_miss.append(i)\n",
    "samplet = np.array(samplet)\n",
    "\n",
    "labelt = [] \n",
    "for line in open(\"../CMAPSSData/RUL_FD00\"+Dataset+\".txt\"):\n",
    "    labelt.append(line.split())\n",
    "labelt = np.cast['int32'](labelt)\n",
    "labelnew = []\n",
    "for i in range(nTest):\n",
    "    if i not in count_miss:\n",
    "        #labelnew.append(labelt[i][0])\n",
    "        labelnew.append(labelt[i][0] if labelt[i][0]<=ConstRUL else ConstRUL)\n",
    "labelt = labelnew\n",
    "labelt=np.array(labelt)\n",
    "\n",
    "'''seed = 2222\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(samples)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(targets)\n",
    "samplet = samplet[np.argsort(labelt)]\n",
    "labelt = labelt[np.argsort(labelt)]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "(17731, 30, 14)\n",
      "(17731,)\n",
      "Testing data\n",
      "(100, 30, 14)\n",
      "(100,)\n",
      "Training data\n",
      "[[[ 0.42168675  0.12579028  0.17049291 ...  0.33333333 -0.27131783\n",
      "   -0.07953604]\n",
      "  [ 0.06024096 -0.02419882  0.37812289 ...  0.16666667 -0.27131783\n",
      "    0.01712234]\n",
      "  [-0.01204819 -0.02419882  0.47467927 ...  0.16666667 -0.11627907\n",
      "   -0.11101906]\n",
      "  ...\n",
      "  [ 0.51204819  0.14453891  0.52464551 ...  0.         -0.62790698\n",
      "   -0.34217067]\n",
      "  [ 0.3253012   0.26444299  0.67623228 ...  0.         -1.\n",
      "   -0.17674676]\n",
      "  [ 0.37349398  0.17462394  0.5658339  ...  0.5        -0.45736434\n",
      "   -0.78099972]]\n",
      "\n",
      " [[ 0.06024096 -0.02419882  0.37812289 ...  0.16666667 -0.27131783\n",
      "    0.01712234]\n",
      "  [-0.01204819 -0.02419882  0.47467927 ...  0.16666667 -0.11627907\n",
      "   -0.11101906]\n",
      "  [-0.09638554 -0.02419882  0.53376097 ...  0.         -0.24031008\n",
      "   -0.2761668 ]\n",
      "  ...\n",
      "  [ 0.3253012   0.26444299  0.67623228 ...  0.         -1.\n",
      "   -0.17674676]\n",
      "  [ 0.37349398  0.17462394  0.5658339  ...  0.5        -0.45736434\n",
      "   -0.78099972]\n",
      "  [ 0.40361446  0.4589056   0.73295071 ...  0.16666667 -0.75193798\n",
      "   -0.26760563]]\n",
      "\n",
      " [[-0.01204819 -0.02419882  0.47467927 ...  0.16666667 -0.11627907\n",
      "   -0.11101906]\n",
      "  [-0.09638554 -0.02419882  0.53376097 ...  0.         -0.24031008\n",
      "   -0.2761668 ]\n",
      "  [ 0.10843373 -0.01809462  0.29068197 ...  0.33333333  0.03875969\n",
      "   -0.28997514]\n",
      "  ...\n",
      "  [ 0.37349398  0.17462394  0.5658339  ...  0.5        -0.45736434\n",
      "   -0.78099972]\n",
      "  [ 0.40361446  0.4589056   0.73295071 ...  0.16666667 -0.75193798\n",
      "   -0.26760563]\n",
      "  [ 0.3313253   0.36995858  0.55064146 ...  0.66666667 -0.53488372\n",
      "   -0.89201878]]\n",
      "\n",
      " [[-0.09638554 -0.02419882  0.53376097 ...  0.         -0.24031008\n",
      "   -0.2761668 ]\n",
      "  [ 0.10843373 -0.01809462  0.29068197 ...  0.33333333  0.03875969\n",
      "   -0.28997514]\n",
      "  [ 0.06024096  0.36516242  0.4409183  ...  0.         -0.45736434\n",
      "   -0.17702292]\n",
      "  ...\n",
      "  [ 0.40361446  0.4589056   0.73295071 ...  0.16666667 -0.75193798\n",
      "   -0.26760563]\n",
      "  [ 0.3313253   0.36995858  0.55064146 ...  0.66666667 -0.53488372\n",
      "   -0.89201878]\n",
      "  [ 0.21686747  0.49204273  0.49493585 ...  0.16666667 -0.76744186\n",
      "   -0.53106877]]\n",
      "\n",
      " [[ 0.10843373 -0.01809462  0.29068197 ...  0.33333333  0.03875969\n",
      "   -0.28997514]\n",
      "  [ 0.06024096  0.36516242  0.4409183  ...  0.         -0.45736434\n",
      "   -0.17702292]\n",
      "  [ 0.31927711  0.06780031  0.22822417 ... -0.16666667 -0.56589147\n",
      "   -0.21264844]\n",
      "  ...\n",
      "  [ 0.3313253   0.36995858  0.55064146 ...  0.66666667 -0.53488372\n",
      "   -0.89201878]\n",
      "  [ 0.21686747  0.49204273  0.49493585 ...  0.16666667 -0.76744186\n",
      "   -0.53106877]\n",
      "  [ 0.59036145  0.2792675   0.68433491 ...  0.33333333 -0.64341085\n",
      "   -0.56365645]]]\n",
      "[4 3 2 1 0]\n",
      "Testing data\n",
      "[[[-0.55421687 -0.61107478 -0.55232951 ... -0.33333333  0.39534884\n",
      "    0.55426678]\n",
      "  [-0.65060241 -0.17680401 -0.75151924 ... -0.33333333  0.28682171\n",
      "    0.14526374]\n",
      "  [-0.55421687 -0.58098975 -0.41458474 ... -0.33333333  0.41085271\n",
      "    0.341066  ]\n",
      "  ...\n",
      "  [-0.46987952  0.10660562 -0.28257934 ... -0.16666667  0.34883721\n",
      "    0.38663353]\n",
      "  [-0.24698795 -0.3381295  -0.24004051 ... -0.16666667  0.51937984\n",
      "    0.11875173]\n",
      "  [-0.34337349 -0.13494659 -0.47029034 ... -0.5         0.27131783\n",
      "    0.56420878]]\n",
      "\n",
      " [[-0.02409639 -0.30978853 -0.32343011 ... -0.33333333  0.37984496\n",
      "    0.25158796]\n",
      "  [-0.1626506  -0.29016787 -0.23869007 ... -0.16666667  0.27131783\n",
      "    0.31593482]\n",
      "  [-0.39156627 -0.29627207 -0.36664416 ... -0.16666667  0.25581395\n",
      "    0.3985087 ]\n",
      "  ...\n",
      "  [-0.40361446 -0.21342926 -0.32039163 ... -0.16666667  0.37984496\n",
      "    0.31759183]\n",
      "  [-0.39156627 -0.39481142 -0.26772451 ... -0.33333333  0.06976744\n",
      "    0.50483292]\n",
      "  [-0.1686747  -0.48027033 -0.03207292 ...  0.16666667 -0.27131783\n",
      "    0.10770505]]\n",
      "\n",
      " [[-0.15662651 -0.05777196 -0.29642134 ... -0.16666667  0.17829457\n",
      "    0.11543772]\n",
      "  [-0.24698795 -0.23348594 -0.11006077 ... -0.16666667  0.1627907\n",
      "    0.1248274 ]\n",
      "  [-0.18072289 -0.24177022 -0.04051317 ... -0.33333333  0.2248062\n",
      "    0.34962717]\n",
      "  ...\n",
      "  [ 0.12048193 -0.27883148  0.05773126 ...  0.16666667 -0.10077519\n",
      "    0.02734051]\n",
      "  [ 0.01204819 -0.03727927 -0.28899392 ...  0.         -0.02325581\n",
      "    0.00303783]\n",
      "  [-0.11445783  0.24133421  0.1215395  ...  0.         -0.03875969\n",
      "    0.28859431]]\n",
      "\n",
      " [[-0.40963855 -0.19032047 -0.56617151 ... -0.66666667  0.42635659\n",
      "    0.32836233]\n",
      "  [-0.62048193 -0.57096141 -0.67555706 ... -0.66666667  0.51937984\n",
      "    0.4084507 ]\n",
      "  [-0.42771084 -0.36908655 -0.486158   ... -0.5         0.95348837\n",
      "    0.48715824]\n",
      "  ...\n",
      "  [-0.04216867 -0.5382603  -0.49729912 ... -0.5         0.44186047\n",
      "    0.08091687]\n",
      "  [-0.3253012  -0.46152169 -0.28865631 ... -0.66666667  0.28682171\n",
      "    0.54045844]\n",
      "  [-0.52409639 -0.39001526 -0.46893991 ... -0.5         0.25581395\n",
      "    0.28500414]]\n",
      "\n",
      " [[-0.30722892 -0.11881404 -0.1144497  ... -0.33333333  0.06976744\n",
      "    0.1996686 ]\n",
      "  [-0.10240964 -0.17680401 -0.13301823 ... -0.16666667  0.14728682\n",
      "    0.11516156]\n",
      "  [-0.02409639 -0.31981687 -0.02295746 ... -0.33333333  0.08527132\n",
      "   -0.12703673]\n",
      "  ...\n",
      "  [ 0.34337349 -0.03597122 -0.17049291 ...  0.16666667 -0.25581395\n",
      "   -0.1413974 ]\n",
      "  [ 0.23493976  0.0442555   0.25286968 ...  0.16666667 -0.19379845\n",
      "    0.03755869]\n",
      "  [ 0.04819277  0.33333333  0.44294396 ...  0.33333333 -0.13178295\n",
      "   -0.1955261 ]]]\n",
      "[125  82  59 117  20]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data\")\n",
    "print(samples.shape)\n",
    "print(targets.shape)\n",
    "print(\"Testing data\")\n",
    "print(samplet.shape)\n",
    "print(labelt.shape)\n",
    "print(\"Training data\")\n",
    "print(samples[-5:,:])\n",
    "print(targets[-5:])\n",
    "print(\"Testing data\")\n",
    "print(samplet[-5:,:])\n",
    "print(labelt[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model\n",
    "\n",
    "CNN model. The model is Dense(ReLU, 100)->Dense(ReLu, 100)->Dense(Linear, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RULCNNModel(TW, FeatureN):\n",
    "    \n",
    "    input_layer = Input(shape=(TW, FeatureN))\n",
    "    y = Reshape((TW, FeatureN, 1), input_shape=(TW, FeatureN, ),name = 'Reshape')(input_layer)\n",
    "\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C1')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C2')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C3')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C4')(y)\n",
    "    #y = Convolution2D(FilterN, FilterL, 1, border_mode='same', init='glorot_normal', activation='tanh', name='C5')(y)\n",
    "    #y = Convolution2D(FilterN, FilterL, 1, border_mode='same', init='glorot_normal', activation='tanh', name='C6')(y)\n",
    "    \n",
    "    y = Conv2D(1, 3, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='Clast')(y)  \n",
    "    \n",
    "    y = Reshape((TW,14))(y)\n",
    "    y = Flatten()(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    \n",
    "    #y = Dense(100, activation='tanh', init='glorot_normal', activity_regularizer=keras.regularizers.l2(0.01),)(y)\n",
    "    y = Dense(100,activation='tanh', kernel_initializer='glorot_normal', name='fc')(y)\n",
    "    y = Dense(1)(y)\n",
    "    \n",
    "    model = Model(inputs = input_layer, outputs = y, name='RUL_CNN_Model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the keras model\n",
    "\n",
    "Fit the Keras model to the data and determine its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0, beta_1=0.5)\n",
    "#DCNN = Model([input_layer], [y])\n",
    "DCNN = RULCNNModel(TW, FeatureN)\n",
    "#DCNN.compile(loss=get_score,optimizer=opt)\n",
    "DCNN.compile(loss='mean_squared_error',optimizer=opt)\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "\n",
    "startTime = time.clock()\n",
    "history = DCNN.fit(samples, targets,nb_epoch=nb_epoch, batch_size=batch_size,verbose=1, \n",
    "                   validation_data=(samplet, labelt), callbacks=[lrate])\n",
    "endTime = time.clock()\n",
    "    \n",
    "#, TensorBoard(log_dir='tmp\\\\tan_4c_4')\n",
    "    \n",
    "#history = DCNN.fit(samples, targets,nb_epoch=nb_epoch, batch_size=batch_size,verbose=1, \n",
    "#                 validation_data=(samplet, labelt), callbacks=[lrate])\n",
    "#history = DCNN.fit(samples, targets,nb_epoch=nb_epoch, batch_size=batch_size,verbose=0, callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "score = DCNN.evaluate(samplet, labelt)\n",
    "y_pred = DCNN.predict(X_test)\n",
    "healtScore = CMAPSAuxFunctions.compute_health_score(y_test, y_pred)\n",
    "\n",
    "print(\"Root Square Mean Error score: {}\".format(np.sqrt(score[0])))\n",
    "print(\"Health score: {}\".format(healtScore))\n",
    "print(\"Elapsed time: {}\".format(endTime - startTime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
